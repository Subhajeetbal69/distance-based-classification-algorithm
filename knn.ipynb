{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors from Scratch\n",
    "## Task 1: Distance-Based Classification\n",
    "\n",
    "This notebook implements KNN from scratch on the Fashion-MNIST dataset with all bonus features:\n",
    "- Multiple distance metrics comparison\n",
    "- Optimized nearest-neighbor search\n",
    "- Decision boundary visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fashion-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Fashion-MNIST\n",
    "print(\"Loading Fashion-MNIST dataset...\")\n",
    "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False, parser='auto')\n",
    "\n",
    "# Normalize pixel values to 0-1\n",
    "X = X / 255.0\n",
    "y = y.astype(int)\n",
    "\n",
    "# Use a subset for faster training (5000 samples)\n",
    "X_subset = X[:5000]\n",
    "y_subset = y[:5000]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_subset, y_subset, test_size=0.2, random_state=42, stratify=y_subset\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features per sample: {X_train.shape[1]}\")\n",
    "\n",
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        \"\"\"\n",
    "        K-Nearest Neighbors classifier\n",
    "        \n",
    "        Parameters:\n",
    "        k: number of neighbors to consider\n",
    "        distance_metric: 'euclidean', 'manhattan', or 'cosine'\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def compute_distance(self, x1, x2):\n",
    "        \"\"\"Compute distance between two samples\"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            dot_product = np.dot(x1, x2)\n",
    "            norm_x1 = np.linalg.norm(x1)\n",
    "            norm_x2 = np.linalg.norm(x2)\n",
    "            return 1 - (dot_product / (norm_x1 * norm_x2 + 1e-10))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        \"\"\"Predict class for a single sample\"\"\"\n",
    "        # Compute distances to all training samples\n",
    "        distances = [self.compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Get indices of k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Get labels of k nearest neighbors\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        # Return most common label\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes for multiple samples\"\"\"\n",
    "        return np.array([self.predict_single(x) for x in X])\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized KNN with Vectorized Distance Computation (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class KNN_Optimized:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def compute_distances_vectorized(self, X_test):\n",
    "        \"\"\"Vectorized distance computation for speed\"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            # Efficient euclidean distance: ||a-b||^2 = ||a||^2 + ||b||^2 - 2*a\u00b7b\n",
    "            sum_X_train = np.sum(self.X_train ** 2, axis=1)\n",
    "            sum_X_test = np.sum(X_test ** 2, axis=1)[:, np.newaxis]\n",
    "            dot_product = np.dot(X_test, self.X_train.T)\n",
    "            distances = np.sqrt(sum_X_test + sum_X_train - 2 * dot_product)\n",
    "            return distances\n",
    "        \n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            # Memory-efficient Manhattan distance\n",
    "            distances = np.zeros((X_test.shape[0], self.X_train.shape[0]))\n",
    "            for i, x_test in enumerate(X_test):\n",
    "                distances[i] = np.sum(np.abs(x_test - self.X_train), axis=1)\n",
    "            return distances\n",
    "        \n",
    "        elif self.distance_metric == 'cosine':\n",
    "            dot_product = np.dot(X_test, self.X_train.T)\n",
    "            norm_test = np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "            norm_train = np.linalg.norm(self.X_train, axis=1, keepdims=True).T\n",
    "            distances = 1 - (dot_product / (norm_test * norm_train + 1e-10))\n",
    "            return distances\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Compute all distances at once\n",
    "        distances = self.compute_distances_vectorized(X)\n",
    "        \n",
    "        # Get k nearest neighbors for each test sample\n",
    "        k_indices = np.argsort(distances, axis=1)[:, :self.k]\n",
    "        \n",
    "        # Get labels of k nearest neighbors\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        # Majority voting\n",
    "        predictions = np.array([Counter(labels).most_common(1)[0][0] \n",
    "                               for labels in k_nearest_labels])\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Effect of K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n=== Testing different K values ===\")\n",
    "k_values = [1, 3, 5, 7, 9, 11, 15]\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNN_Optimized(k=k, distance_metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"K={k}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Plot K vs Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, accuracies, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('K Value', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Effect of K on KNN Accuracy', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_values)\n",
    "plt.tight_layout()\n",
    "plt.savefig('k_value_effect.png', dpi=150)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Compare Distance Metrics (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n=== Comparing Distance Metrics ===\")\n",
    "distance_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "metric_accuracies = []\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    knn = KNN_Optimized(k=5, distance_metric=metric)\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_test, y_test)\n",
    "    metric_accuracies.append(accuracy)\n",
    "    print(f\"{metric.capitalize()}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Plot Distance Metric Comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(distance_metrics, metric_accuracies, color=['#2ecc71', '#3498db', '#e74c3c'], alpha=0.8)\n",
    "plt.xlabel('Distance Metric', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Comparison of Distance Metrics (K=5)', fontsize=14)\n",
    "plt.ylim([min(metric_accuracies) - 0.02, max(metric_accuracies) + 0.02])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "for i, acc in enumerate(metric_accuracies):\n",
    "    plt.text(i, acc + 0.005, f'{acc:.4f}', ha='center', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('distance_metrics_comparison.png', dpi=150)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Speed Optimization Comparison (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n=== Comparing Naive vs Optimized Implementation ===\")\n",
    "\n",
    "# Test on small subset for fair comparison\n",
    "X_test_small = X_test[:100]\n",
    "y_test_small = y_test[:100]\n",
    "\n",
    "# Naive implementation\n",
    "knn_naive = KNN(k=5, distance_metric='euclidean')\n",
    "knn_naive.fit(X_train, y_train)\n",
    "start = time.time()\n",
    "acc_naive = knn_naive.score(X_test_small, y_test_small)\n",
    "time_naive = time.time() - start\n",
    "\n",
    "# Optimized implementation\n",
    "knn_opt = KNN_Optimized(k=5, distance_metric='euclidean')\n",
    "knn_opt.fit(X_train, y_train)\n",
    "start = time.time()\n",
    "acc_opt = knn_opt.score(X_test_small, y_test_small)\n",
    "time_opt = time.time() - start\n",
    "\n",
    "print(f\"Naive KNN: {time_naive:.3f}s, Accuracy: {acc_naive:.4f}\")\n",
    "print(f\"Optimized KNN: {time_opt:.3f}s, Accuracy: {acc_opt:.4f}\")\n",
    "print(f\"Speedup: {time_naive/time_opt:.2f}x\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train final model with best parameters\n",
    "best_k = k_values[np.argmax(accuracies)]\n",
    "best_metric = distance_metrics[np.argmax(metric_accuracies)]\n",
    "\n",
    "print(f\"\\n=== Final Model ===\")\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Metric: {best_metric}\")\n",
    "\n",
    "final_knn = KNN_Optimized(k=best_k, distance_metric=best_metric)\n",
    "final_knn.fit(X_train, y_train)\n",
    "y_pred = final_knn.predict(X_test)\n",
    "final_accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Misclassified Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find misclassified samples\n",
    "misclassified_indices = np.where(y_pred != y_test)[0]\n",
    "print(f\"\\nNumber of misclassified samples: {len(misclassified_indices)}\")\n",
    "\n",
    "# Show some misclassified examples\n",
    "num_show = min(10, len(misclassified_indices))\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_show):\n",
    "    idx = misclassified_indices[i]\n",
    "    image = X_test[idx].reshape(28, 28)\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f'True: {class_names[y_test[idx]]}\\nPred: {class_names[y_pred[idx]]}', \n",
    "                      fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('misclassified_samples.png', dpi=150)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute confusion matrix\n",
    "num_classes = 10\n",
    "confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "for true_label, pred_label in zip(y_test, y_pred):\n",
    "    confusion_matrix[true_label, pred_label] += 1\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(confusion_matrix, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        plt.text(j, i, str(confusion_matrix[i, j]),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if confusion_matrix[i, j] > confusion_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Class-wise accuracy\n",
    "print(\"\\nClass-wise Accuracy:\")\n",
    "for i in range(num_classes):\n",
    "    class_accuracy = confusion_matrix[i, i] / np.sum(confusion_matrix[i, :])\n",
    "    print(f\"{class_names[i]:15s}: {class_accuracy:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary Visualization (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Reduce to 2D using PCA for visualization\n",
    "print(\"\\n=== Visualizing Decision Boundaries ===\")\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train)\n",
    "X_test_2d = pca.transform(X_test)\n",
    "\n",
    "# Train KNN on 2D data\n",
    "knn_2d = KNN_Optimized(k=5, distance_metric='euclidean')\n",
    "knn_2d.fit(X_train_2d, y_train)\n",
    "accuracy_2d = knn_2d.score(X_test_2d, y_test)\n",
    "print(f\"Accuracy on 2D projection: {accuracy_2d:.4f}\")\n",
    "\n",
    "# Create mesh for decision boundaries\n",
    "h = 0.5  # step size in the mesh\n",
    "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on mesh\n",
    "print(\"Computing decision boundaries (this may take a moment)...\")\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10', levels=np.arange(11) - 0.5)\n",
    "\n",
    "# Plot training points\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for i in range(10):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(X_train_2d[mask, 0], X_train_2d[mask, 1], \n",
    "               c=[colors[i]], label=class_names[i], \n",
    "               edgecolors='black', linewidth=0.5, s=50, alpha=0.7)\n",
    "\n",
    "plt.xlabel('First Principal Component', fontsize=12)\n",
    "plt.ylabel('Second Principal Component', fontsize=12)\n",
    "plt.title(f'KNN Decision Boundaries (K={best_k}) - PCA Projection', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_boundaries.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: Fashion-MNIST (subset)\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nBest K value: {best_k}\")\n",
    "print(f\"Best distance metric: {best_metric}\")\n",
    "print(f\"Final accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Misclassified samples: {len(misclassified_indices)} / {len(y_test)}\")\n",
    "print(f\"\\nOptimization speedup: {time_naive/time_opt:.2f}x\")\n",
    "print(\"=\"*50)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}